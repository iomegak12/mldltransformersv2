{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import spacy \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/spam.csv',encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['label','text']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "tqdm.pandas(desc='Processing with spaCy')\n",
    "spacy_results = df['text'].progress_map(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode with Sentence Transformers\n",
    "\n",
    "sentence_bert = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "# tqdm.pandas(desc='Applying sentence-bert')\n",
    "# vectors = df['text'].progress_map(model.encode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swifter\n",
    "\n",
    "%time \n",
    "\n",
    "vectors_swifter = df['text'].swifter.apply(sentence_bert.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['raw_spacy'] = spacy_results\n",
    "df['raw_pos'] = df['raw_spacy'].swifter.apply(lambda x: ' '.join([t.pos_ for t in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence-bert'] = vectors_swifter\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.label.swifter.apply(lambda x : 1 if x =='spam' else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['raw_spacy'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_embeddings(embeddings):\n",
    "    import numpy as np\n",
    "    return np.vstack(embeddings.values)\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('bag of ngrams', TfidfVectorizer(ngram_range=(1, 2), max_features=3000), 'text'),\n",
    "    ('bag of POS', CountVectorizer(ngram_range=(1, 2)), 'raw_pos'),\n",
    "    # Lambda functions cannot be pickled\n",
    "    ('sentence bert', FunctionTransformer(stack_embeddings), 'sentence-bert'),\n",
    "    # ('bag of NER types', CountVectorizer(ngram_range=(1, 2)), 'raw_ner'),\n",
    "    # ('ngrams before', TfidfVectorizer(ngram_range=(1, 2), max_features=3000), 'raw_before'),\n",
    "    # ('ngrams after', TfidfVectorizer(ngram_range=(1, 2), max_features=3000), 'raw_after')    \n",
    "],remainder='passthrough')\n",
    "\n",
    "# lm = LogisticRegression()\n",
    "xgb = XGBClassifier(random_state=0)\n",
    "\n",
    "# pipeline = Pipeline([('transformer', ct), ('classifier', lm)])\n",
    "pipeline = Pipeline([('transformer', ct), ('classifier', xgb)])\n",
    "\n",
    "\n",
    "y,X = train_df.pop('label'),train_df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%time model = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# filename = 'model.sav'\n",
    "# joblib.dump(model, filename)\n",
    "import dill\n",
    "\n",
    "\n",
    "pkl_filename = \"../Models/model.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    dill.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ../Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_filename,'rb') as file:\n",
    "    loaded_model = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_df(input_text):\n",
    "\n",
    "    model_input_dict = {}\n",
    "    input_row_list = []\n",
    "    \n",
    "\n",
    "    spacy_raw = nlp(input_text)\n",
    "    # pos_tags = [t.pos_ for t in spacy_raw]\n",
    "\n",
    "    model_input_dict['text'] = input_text\n",
    "    model_input_dict['raw_pos'] =  ' '.join([t.pos_ for t in spacy_raw])\n",
    "    model_input_dict['sentence-bert'] = sentence_bert.encode(input_text)\n",
    "\n",
    "    input_row_list.append(model_input_dict)\n",
    "\n",
    "    model_input_df = pd.DataFrame(input_row_list)\n",
    "    return model_input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C\\'s'\n",
    "# make_inference_df(sample_text)\n",
    "loaded_model.predict(make_inference_df(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text_2 = 'Nah I don\\'t think he goes to usf, he lives around here though'\n",
    "print(sample_text_2)\n",
    "loaded_model.predict(make_inference_df(sample_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
